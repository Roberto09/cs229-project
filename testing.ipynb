{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "04fbe6e0-f81d-4c43-aeaf-28bd72d448a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "93d3ea03-fcfc-4c9c-ae03-17ce77cb959e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../LLM-Pruner/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e7a4a243-0c92-4250-9090-c204569f8b6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59281c60-c5ca-4ca2-a9fe-ba74be9e6c23",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d2485f0e-a34a-4272-b8e1-e726781a09cf",
   "metadata": {},
   "source": [
    "## Model and Tokenizer Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1672e217-f6ee-47f8-a8b8-82c33b061d95",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = \"microsoft/phi-1_5\"\n",
    "model_revision = \"349cf8b5e81fd5f791d1740da5de1313a0419bbd\" # latest as of feb 1st"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "36d07245-c822-41b4-bf35-f902ec3fa607",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_id, trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e1863cef-0ad1-4f69-b271-fe4078d72b96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50295"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab = tokenizer.get_vocab()\n",
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d8531b75-5a93-438c-8b70-b36fab79b4d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    revision=model_revision,\n",
    "    trust_remote_code=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a24eaf03-2532-4889-8453-ea7e967f6849",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d57316ae-a64e-4b09-9185-dd76066a87d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from LLMPruner.datasets.example_samples import get_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6423cbb4-d521-4e9e-95e7-0d4bc0d36a1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "examples = get_examples(\"bookcorpus\", tokenizer, n_samples=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c2ef80b8-30bd-4628-a631-51a692c662db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1946,   262,  1772,  ...,  4490,  7541,   837],\n",
       "        [ 3872,   837,   339,  ...,   340,   714,   307],\n",
       "        [   82,  3656,   730,  ...,   329,   257,   845],\n",
       "        ...,\n",
       "        [  484,   537,   499,  ...,   502,  7263,   287],\n",
       "        [  286,   683,   290,  ...,  7812,   465, 32870],\n",
       "        [13033,   286,   262,  ...,   262, 40445,   837]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6646aebb-9bec-4c11-b611-07763769e908",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = model.forward(\n",
    "    examples, \n",
    "    # This is ok, labels are shifted in forward function\n",
    "    labels=examples\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "df1bd19c-d5eb-4480-84b4-8efea5153932",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" bucked in my hand as i emptied the clip, and from a great distance i heard someone screaming, but it wasn't him screaming, it was me screaming, me and everybody else who was left, if there was anybody left, all of us helpless, hopeless, stupid humans screaming, because we got it wrong, we got it all wrong, there was no alien swarm descending from the sky in their flying saucers or big metal walkers like something out of star wars or cute little wrinkly e.t.s who just wanted to pluck a couple of leaves, eat some reese's pieces, and go\""
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(examples[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2d06e1fb-e1e5-4730-bcf1-7d74cd85481c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"led off the seatbag I tried the bagboard and the the distance distance, could the say. and i was tooigh me,, it was me.. and screaming my else in was in in and you was a left, we of us were, helpless, and,,. and we were caught,, and got it wrong wrong, and was no one,, on the sky, the spaceship machineucers, their flying birdsers, in out of a Trek, something little alienly aliensw\\n.c.'s wanted to beop our few of hairs from or a berriesind'ss crack of and go back\""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(res.logits[3].argmax(dim=-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d26b047-8246-40a3-9b5b-0efab5303772",
   "metadata": {},
   "source": [
    "## Model importance computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "00e484bf-85ca-4593-ac6d-d87f8d582e07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# res = model.forward(\n",
    "#     examples, \n",
    "#     # This is ok, labels are shifted in forward function\n",
    "#     labels=examples\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a234cd9a-91b3-41da-97c2-39fa57708d9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# res.loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "08868941-d331-415f-92d0-19c8e0e2cc95",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mlps(model):\n",
    "    layers = model.get_submodule(\"model\").get_submodule(\"layers\")\n",
    "    return [layer.get_submodule(\"mlp\") for layer in layers]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20f0d974-9302-4dfe-8749-a8dc3d642dd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_acc_grad(model, examples, mlps):\n",
    "    # Computes the second term of the taylor expansion\n",
    "    params = [list(mlp.parameters()) for mlp in mlps]\n",
    "    params = itertools.chain.from_iterable(params) # flatten list\n",
    "    \n",
    "    for example in examples:\n",
    "        example = example.unsqueeze(0)\n",
    "        loss = model(example, labels=examples)\n",
    "        loss.backward()\n",
    "        for param in params: # for all the weights\n",
    "            num_examples = examples.shape[0]\n",
    "            sq_grad = param.grad * param.grad / num_examples\n",
    "            if hasattr(param, \"acc_grad\"):\n",
    "                param.acc_grad += sq_grad\n",
    "            else:\n",
    "                param.acc_grad = sq_grad\n",
    "        model.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "3a0059ca-b3e3-4068-949d-a25810978f8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def compute_mlp_importance(mlps):\n",
    "    # computes importance for hidden layers of MLP\n",
    "    importances = []\n",
    "    for mlp in mlps:\n",
    "        fc1 = mlp.fc1\n",
    "        fc2 = mlp.fc2\n",
    "        # compute importance of inputs to hidden\n",
    "        salience_w1 = fc1.weight * fc1.weight.grad\n",
    "        salience_w2 = fc2.weight * fc2.weight.grad\n",
    "        \n",
    "        salience_w1 = salience_w1 - 0.5 * fc1.weight * fc1.weight.acc_grad * fc1.weight\n",
    "        salience_w2 = salience_w2 - 0.5 * fc2.weight * fc2.weight.acc_grad * fc2.weight\n",
    "\n",
    "        importance_w1_component =  salience_w1.abs().sum(dim=1)\n",
    "        importance_w2_component =  salience_w2.abs().sum(dim=0)\n",
    "\n",
    "        # analogous to group reduction?\n",
    "        importance = importance_w1_component + importance_w2_component\n",
    "        importances.append(importance)\n",
    "    return importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "346e0f34-2a0d-4794-ab5e-4647ce599c4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_importances(model, examples):\n",
    "    # returns importance for mlp examples\n",
    "    mlps = get_mlps(model)\n",
    "    compute_acc_grad(model, examples, mlps) # estimates hessian term of importance\n",
    "    loss = model(examples, labels=examples).loss\n",
    "    loss.backward()\n",
    "    importances = compute_importance(examples, labels=examples)\n",
    "    return importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "1827885f-f629-4540-9d34-0b3342e79772",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 128])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "examples.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e99336a-4f79-4a75-966d-8df470c54fb3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8532b5ba-1a25-4045-ae07-90fcd385a010",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eee1e597-15d6-477b-a60f-7c0179a8d245",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "02d8cf29-abc7-483d-922d-73ef4a14c008",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlps = get_mlps(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ad1993c9-f143-4dad-bc53-852e8cb2c8a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = mlps[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d2f2da00-c9f8-4c92-821e-60f869e6aef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "fc1 = mlp.get_submodule(\"fc1\")\n",
    "fc2 = mlp.get_submodule(\"fc2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e07aa8d3-3582-4a81-bfdb-9ae978f7209f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear(in_features=2048, out_features=8192, bias=True)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fc1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81f2d16c-065d-4aa2-a127-13d97905c1c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "452f72e3-b57d-4ff2-a551-5b9b48b35f55",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_importance(mlp):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c21a7a73-ecc5-4b2c-9fca-f4d4acd30830",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d97fee8-ed90-47ec-8a4c-5d34a4bda165",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "8c66cb9c-d540-459a-be49-15c0a03d9605",
   "metadata": {},
   "outputs": [],
   "source": [
    "modules = list(model.modules())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "98c7b3e8-4a3c-443e-a151-37bd0fe5c203",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = model.get_submodule(\"model\").get_submodule(\"layers\")[0].get_submodule(\"mlp\").get_submodule(\"fc1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "3e4ecb25-2050-47f5-be1c-0ed662b9f30d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8192, 2048])"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(x.parameters())[0].grad.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e0b1e71-7611-4ad2-9a7b-ed6a120a9994",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ca39dff-818e-49de-b27b-621c1a587c40",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f26cc2cd-7d85-4232-a24a-44f547c8ba85",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
