{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from weighted_svd_utils import weighted_frobenious, get_svd, rank_r, get_svd_lora, toy_correlated_matrix, toy_two_subspace_matrix, toy_seven_subspace_matrix, toy_seven_subspace_matrix_unqual_size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flops_from_svd(U, S, V):\n",
    "    ret = 2 * (V.shape[0] * V.shape[1] + U.shape[0] * U.shape[1]) + S.shape[0] if U != None and S != None and V != None else 0\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_optimal_rank_allocation_F2(mat1, mat2, flops):\n",
    "    mat1_flops = 2 * mat1.shape[0] * mat1.shape[1] if mat1 != None else 0.0\n",
    "    mat2_flops = 2 * mat2.shape[0] * mat2.shape[1] if mat2 != None else 0.0\n",
    "    u1, s1, v1 = get_svd(mat1) if mat1 != None else (None, None, None)\n",
    "    u2, s2, v2 = get_svd(mat2) if mat2 != None else (None, None, None)\n",
    "    svd1_flops = flops_from_svd(u1, s1, v1)\n",
    "    svd2_flops = flops_from_svd(u2, s2, v2)\n",
    "    flops_per_sv_1 = 2 * v1.shape[0] + 2 * u1.shape[0] if mat1 != None else 0.0\n",
    "    flops_per_sv_2 = 2 * v2.shape[0] + 2 * u2.shape[0] if mat2 != None else 0.0\n",
    "\n",
    "    #F2_loss_1 = torch.diag(s1) if mat1 != None else []\n",
    "    F2_loss_1 = [s*s for s in s1] if mat1 != None else [] \n",
    "    #F2_loss_2 = torch.diag(s2) if mat2 != None else []\n",
    "    F2_loss_2 = [s*s for s in s2] if mat2 != None else []\n",
    "\n",
    "    r1 = s1.shape[0] if mat1 != None else 0\n",
    "    r2 = s2.shape[0] if mat2 != None else 0\n",
    "\n",
    "    min_F2_loss = torch.inf\n",
    "\n",
    "    if (mat1 == None and mat2 == None):\n",
    "        print(\"Warning! Both matrices empty!\")\n",
    "\n",
    "    # Find the best split given that both matrices are SV-decomposed\n",
    "    if (mat1 != None and mat2 != None):\n",
    "        flops_both_svd = svd1_flops + svd2_flops\n",
    "        F2_loss_both_svd = 0\n",
    "        i1_both_svd = r1 - 1\n",
    "        i2_both_svd = r2 - 1\n",
    "        while flops_both_svd > flops:\n",
    "            F2_per_flops_1 = F2_loss_1[i1_both_svd] / flops_per_sv_1\n",
    "            F2_per_flops_2 = F2_loss_2[i2_both_svd] / flops_per_sv_2\n",
    "\n",
    "            if (F2_per_flops_1 < F2_per_flops_2 or i2_both_svd == 0) and i1_both_svd > 0:\n",
    "                F2_loss_both_svd += F2_loss_1[i1_both_svd]\n",
    "                flops_both_svd -= flops_per_sv_1\n",
    "                i1_both_svd -= 1\n",
    "            elif i2_both_svd > 0:\n",
    "                F2_loss_both_svd += F2_loss_2[i2_both_svd]\n",
    "                flops_both_svd -= flops_per_sv_2\n",
    "                i2_both_svd -= 1\n",
    "\n",
    "        r1_optimal = i1_both_svd + 1\n",
    "        r2_optimal = i2_both_svd + 1\n",
    "        min_F2_loss = F2_loss_both_svd\n",
    "        flops1 = r1_optimal * flops_per_sv_1\n",
    "        flops2 = r2_optimal * flops_per_sv_2\n",
    "\n",
    "    # Find the best split given that only mat1 is SV-decomposed\n",
    "    if mat1 != None:\n",
    "        flops_mat1_svd = svd1_flops + mat2_flops\n",
    "        F2_loss_mat1_svd = 0\n",
    "        i1_mat1_svd = r1 - 1\n",
    "        while flops_mat1_svd > flops and i1_mat1_svd > 0:\n",
    "            F2_loss_mat1_svd += F2_loss_1[i1_mat1_svd]\n",
    "            flops_mat1_svd -= flops_per_sv_1\n",
    "            i1_mat1_svd -= 1\n",
    "\n",
    "        if i1_mat1_svd <= 1:\n",
    "            F2_loss_mat1_svd = torch.inf\n",
    "\n",
    "        if F2_loss_mat1_svd < min_F2_loss:\n",
    "            r1_optimal = i1_mat1_svd + 1\n",
    "            r2_optimal = r2\n",
    "            min_F2_loss = F2_loss_mat1_svd\n",
    "            flops1 = r1_optimal * flops_per_sv_1\n",
    "            flops2 = mat2_flops\n",
    "\n",
    "    # Find the best split given that only mat2 is SV-decomposed\n",
    "    if mat2 != None:\n",
    "        flops_mat2_svd = mat1_flops + svd2_flops\n",
    "        F2_loss_mat2_svd = 0\n",
    "        i2_mat2_svd = r2 - 1\n",
    "        while flops_mat2_svd > flops and i2_mat2_svd > 0:\n",
    "            F2_loss_mat2_svd += F2_loss_2[i2_mat2_svd]\n",
    "            flops_mat2_svd -= flops_per_sv_2\n",
    "            i2_mat2_svd -= 1\n",
    "\n",
    "        if i2_mat2_svd <= 1:\n",
    "                F2_loss_mat2_svd = torch.inf\n",
    "\n",
    "        if F2_loss_mat2_svd < min_F2_loss:\n",
    "            r1_optimal = r1\n",
    "            r2_optimal = i2_mat2_svd + 1\n",
    "            min_F2_loss = F2_loss_mat2_svd\n",
    "            flops1 = mat1_flops\n",
    "            flops2 = r2_optimal * flops_per_sv_2\n",
    "\n",
    "    return (min_F2_loss, r1_optimal, r2_optimal, flops1, flops2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_proj_loss_F2(A_tuple_full, group1, group2, flops):\n",
    "    A_tuple_1 = [A_tuple_full[idx] for idx, row in group1]\n",
    "    A_tuple_2 = [A_tuple_full[idx] for idx, row in group2]\n",
    "\n",
    "    mat1 = torch.stack([row for idx, row in group1]) if group1 else None\n",
    "    mat2 = torch.stack([row for idx, row in group2]) if group2 else None\n",
    "\n",
    "    F2_loss, r1_optimal, r2_optimal, flops1, flops2 = find_optimal_rank_allocation_F2(mat1, mat2, flops)\n",
    "\n",
    "    # Check if F2 loss from singular values matches actual F2 of the difference\n",
    "    lora_1 = get_svd_lora(mat1, r1_optimal) if A_tuple_1 else None\n",
    "    lora_2 = get_svd_lora(mat2, r2_optimal) if A_tuple_2 else None\n",
    "    A_partial_1 = torch.stack([row for idx, row in A_tuple_1]) if A_tuple_1 else None\n",
    "    A_partial_2 = torch.stack([row for idx, row in A_tuple_2]) if A_tuple_2 else None\n",
    "    F_loss_1 = weighted_frobenious(A_partial_1, lora_1) if A_tuple_1 else 0.0\n",
    "    F_loss_2 = weighted_frobenious(A_partial_2, lora_2) if A_tuple_2 else 0.0\n",
    "    F2_loss_actual = F_loss_1 * F_loss_1 + F_loss_2 * F_loss_2\n",
    "\n",
    "    if torch.abs(F2_loss - F2_loss_actual) > 0.5:\n",
    "        print(f\"Warning! F2 losses dont match: {F2_loss} vs {F2_loss_actual}\")\n",
    "\n",
    "    return F2_loss, r1_optimal, r2_optimal, flops1, flops2\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimal_row_to_move_F2(A_tuple_full, sender, receiver, flops):\n",
    "    # current_best_F2_loss, _, _ = get_proj_loss_F2(A_tuple_full, sender, receiver, flops)\n",
    "    current_best_F2_loss = torch.inf\n",
    "    current_best_tuple = None\n",
    "    for tuple in sender:\n",
    "        s = list(sender)\n",
    "        r = list(receiver)\n",
    "\n",
    "        r.append(tuple)\n",
    "        s.remove(tuple)\n",
    "        F2_loss, _, _, _, _ = get_proj_loss_F2(A_tuple_full, s, r, flops)\n",
    "        if F2_loss < current_best_F2_loss:\n",
    "            current_best_F2_loss = F2_loss\n",
    "            current_best_tuple = tuple\n",
    "\n",
    "    return current_best_tuple, current_best_F2_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def greedy_splitting_rows_F2(A, flops=None, printdepth = 1):\n",
    "\n",
    "    # Check if A is a single vector\n",
    "    if A.shape[0] == 1:\n",
    "        print(\"Attempting to split a single vector. Returning vector with zero loss.\")\n",
    "        return 0.0, 2 * A.shape[0] * A.shape[1]\n",
    "\n",
    "    if flops == None:\n",
    "        A_flops = 2 * A.shape[0] * A.shape[1]\n",
    "        flops = 0.5 * A_flops\n",
    "\n",
    "    print(f\"Depth: {printdepth}\")\n",
    "\n",
    "    A_tuple_full = [(i, row) for i, row in enumerate(A)]\n",
    "\n",
    "    sender_idx = 1 # 1 means group1, 2 means group2\n",
    "    optimal_group1 = list(A_tuple_full)\n",
    "    optimal_group2 = []\n",
    "\n",
    "    current_best_F2_loss, _, _, _, _ = get_proj_loss_F2(A_tuple_full, optimal_group1, optimal_group2, flops)\n",
    "    single_svd_F2_loss = current_best_F2_loss # For debugging, can remove later\n",
    "    print(f\"Loss from simple SVD: {single_svd_F2_loss}\")\n",
    "\n",
    "    while True:\n",
    "        current_best_F2_loss_for_direction, _, _, _, _ = get_proj_loss_F2(A_tuple_full, optimal_group1, optimal_group2, flops)\n",
    "        optimal_group1_for_direction = list(optimal_group1)\n",
    "        optimal_group2_for_direction = list(optimal_group2)\n",
    "        groups = [list(optimal_group1), list(optimal_group2)]\n",
    "        sender = groups[sender_idx - 1]\n",
    "        receiver = groups[-sender_idx]\n",
    "        while sender:\n",
    "            row_to_move, F2_loss = optimal_row_to_move_F2(A_tuple_full, sender, receiver, flops)\n",
    "            sender.remove(row_to_move)\n",
    "            receiver.append(row_to_move)\n",
    "            if F2_loss < current_best_F2_loss_for_direction:\n",
    "                optimal_group1_for_direction = list(groups[0])\n",
    "                optimal_group2_for_direction = list(groups[1])\n",
    "                current_best_F2_loss_for_direction = F2_loss\n",
    "\n",
    "        print(f\"Loss for direction: {current_best_F2_loss_for_direction}\")\n",
    "\n",
    "        if current_best_F2_loss_for_direction < current_best_F2_loss:\n",
    "            current_best_F2_loss = current_best_F2_loss_for_direction\n",
    "            optimal_group1 = list(optimal_group1_for_direction)\n",
    "            optimal_group2 = list(optimal_group2_for_direction)\n",
    "            sender_idx = 2 if sender_idx == 1 else 1\n",
    "            continue\n",
    "        else:\n",
    "            print(\"Optimal split found. Proceeding to split sub-matrices.\")\n",
    "            break\n",
    "\n",
    "    F2_loss, r1_optimal, r2_optimal, flops1, flops2 = get_proj_loss_F2(A_tuple_full, optimal_group1, optimal_group2, flops)\n",
    "    print(f\"Size of group 1: {len(optimal_group1)}\\nSize of group 2: {len(optimal_group2)}\")\n",
    "    print(f\"Rank of matrix 1: {r1_optimal}\\nRank of matrix 2: {r2_optimal}\")\n",
    "\n",
    "    if optimal_group1 and optimal_group2:\n",
    "        remainderflops = flops - flops1 - flops2 # TODO: Implement efficient usage of remainder flops in another branches\n",
    "        if remainderflops < 0:\n",
    "            print(\"Warning: Used more flops than allocated!\")\n",
    "        if r2_optimal <= 1:\n",
    "            flops1 += remainderflops\n",
    "        elif r1_optimal <= 1:\n",
    "            flops2 += remainderflops\n",
    "        else:\n",
    "            flops1 += int(remainderflops * 0.5)\n",
    "            flops2 += remainderflops - int(remainderflops * 0.5)\n",
    "\n",
    "        mat1 = torch.stack([row for idx, row in optimal_group1])\n",
    "        mat2 = torch.stack([row for idx, row in optimal_group2])\n",
    "        print(f\"Splitting sub-matrix 1 of depth = {printdepth} with {flops1} flops\")\n",
    "        F2_loss_1, flops1_actual = greedy_splitting_rows_F2(mat1, flops1, printdepth + 1)\n",
    "        print(f\"Splitting sub-matrix 2 of depth = {printdepth} with {flops2} flops\")\n",
    "        F2_loss_2, flops2_actual = greedy_splitting_rows_F2(mat2, flops2, printdepth + 1)\n",
    "        total_F2_loss = F2_loss_1 + F2_loss_2\n",
    "        total_actual_flops = flops1_actual + flops2_actual\n",
    "        return total_F2_loss, total_actual_flops\n",
    "    else:\n",
    "        print(\"No matrices to split.\")\n",
    "        flops1_actual = flops1\n",
    "        flops2_actual = flops2\n",
    "        total_F2_loss = F2_loss\n",
    "        total_actual_flops = flops1_actual + flops2_actual\n",
    "        return total_F2_loss, total_actual_flops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A = toy_seven_subspace_matrix(80, 210, 12, True)\n",
    "A = toy_seven_subspace_matrix_unqual_size(250, 320, 5, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "320"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Depth: 1\n",
      "Loss from simple SVD: 20796.478515625\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m total_F2_loss, total_actual_flops \u001b[38;5;241m=\u001b[39m \u001b[43mgreedy_splitting_rows_F2\u001b[49m\u001b[43m(\u001b[49m\u001b[43mA\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[6], line 32\u001b[0m, in \u001b[0;36mgreedy_splitting_rows_F2\u001b[0;34m(A, flops, printdepth)\u001b[0m\n\u001b[1;32m     30\u001b[0m receiver \u001b[38;5;241m=\u001b[39m groups[\u001b[38;5;241m-\u001b[39msender_idx]\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m sender:\n\u001b[0;32m---> 32\u001b[0m     row_to_move, F2_loss \u001b[38;5;241m=\u001b[39m \u001b[43moptimal_row_to_move_F2\u001b[49m\u001b[43m(\u001b[49m\u001b[43mA_tuple_full\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msender\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreceiver\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflops\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     33\u001b[0m     sender\u001b[38;5;241m.\u001b[39mremove(row_to_move)\n\u001b[1;32m     34\u001b[0m     receiver\u001b[38;5;241m.\u001b[39mappend(row_to_move)\n",
      "Cell \u001b[0;32mIn[5], line 11\u001b[0m, in \u001b[0;36moptimal_row_to_move_F2\u001b[0;34m(A_tuple_full, sender, receiver, flops)\u001b[0m\n\u001b[1;32m      9\u001b[0m r\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28mtuple\u001b[39m)\n\u001b[1;32m     10\u001b[0m s\u001b[38;5;241m.\u001b[39mremove(\u001b[38;5;28mtuple\u001b[39m)\n\u001b[0;32m---> 11\u001b[0m F2_loss, _, _, _, _ \u001b[38;5;241m=\u001b[39m \u001b[43mget_proj_loss_F2\u001b[49m\u001b[43m(\u001b[49m\u001b[43mA_tuple_full\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflops\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m F2_loss \u001b[38;5;241m<\u001b[39m current_best_F2_loss:\n\u001b[1;32m     13\u001b[0m     current_best_F2_loss \u001b[38;5;241m=\u001b[39m F2_loss\n",
      "Cell \u001b[0;32mIn[4], line 8\u001b[0m, in \u001b[0;36mget_proj_loss_F2\u001b[0;34m(A_tuple_full, group1, group2, flops)\u001b[0m\n\u001b[1;32m      5\u001b[0m mat1 \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mstack([row \u001b[38;5;28;01mfor\u001b[39;00m idx, row \u001b[38;5;129;01min\u001b[39;00m group1]) \u001b[38;5;28;01mif\u001b[39;00m group1 \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m      6\u001b[0m mat2 \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mstack([row \u001b[38;5;28;01mfor\u001b[39;00m idx, row \u001b[38;5;129;01min\u001b[39;00m group2]) \u001b[38;5;28;01mif\u001b[39;00m group2 \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m F2_loss, r1_optimal, r2_optimal, flops1, flops2 \u001b[38;5;241m=\u001b[39m \u001b[43mfind_optimal_rank_allocation_F2\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmat1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmat2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflops\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# Check if F2 loss from singular values matches actual F2 of the difference\u001b[39;00m\n\u001b[1;32m     11\u001b[0m lora_1 \u001b[38;5;241m=\u001b[39m get_svd_lora(mat1, r1_optimal) \u001b[38;5;28;01mif\u001b[39;00m A_tuple_1 \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[3], line 4\u001b[0m, in \u001b[0;36mfind_optimal_rank_allocation_F2\u001b[0;34m(mat1, mat2, flops)\u001b[0m\n\u001b[1;32m      2\u001b[0m mat1_flops \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;241m*\u001b[39m mat1\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m*\u001b[39m mat1\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m mat1 \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m0.0\u001b[39m\n\u001b[1;32m      3\u001b[0m mat2_flops \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;241m*\u001b[39m mat2\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m*\u001b[39m mat2\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m mat2 \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m0.0\u001b[39m\n\u001b[0;32m----> 4\u001b[0m u1, s1, v1 \u001b[38;5;241m=\u001b[39m \u001b[43mget_svd\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmat1\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m mat1 \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m (\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m      5\u001b[0m u2, s2, v2 \u001b[38;5;241m=\u001b[39m get_svd(mat2) \u001b[38;5;28;01mif\u001b[39;00m mat2 \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m (\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m      6\u001b[0m svd1_flops \u001b[38;5;241m=\u001b[39m flops_from_svd(u1, s1, v1)\n",
      "File \u001b[0;32m~/cs229-project/weighted_svd_utils.py:26\u001b[0m, in \u001b[0;36mget_svd\u001b[0;34m(W, use_cuda)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_cuda:\n\u001b[1;32m     25\u001b[0m     W \u001b[38;5;241m=\u001b[39m W\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mclone()\u001b[38;5;241m.\u001b[39mcuda()\n\u001b[0;32m---> 26\u001b[0m svd \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msvd\u001b[49m\u001b[43m(\u001b[49m\u001b[43mW\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m svd\u001b[38;5;241m.\u001b[39mU, svd\u001b[38;5;241m.\u001b[39mS, svd\u001b[38;5;241m.\u001b[39mV\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "total_F2_loss, total_actual_flops = greedy_splitting_rows_F2(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(5179.2622)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_F2_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31008.0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_actual_flops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "svd_F2_loss, svd_r1, _, svd_flops, _ = find_optimal_rank_allocation_F2(A, None, 896*250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svd_F2_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "128"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svd_r1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "96768"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svd_flops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
